pipeline = "make_pipeline" op elements cm estimator cp
elements = (preprocessor cm elements) / preprocessor
preprocessor = sklearn_cluster_featureagglomeration / sklearn_decomposition_fastica / sklearn_decomposition_pca / sklearn_feature_selection_selectfwe / sklearn_feature_selection_selectkbest / sklearn_feature_selection_selectpercentile / sklearn_feature_selection_variancethreshold / sklearn_kernel_approximation_nystroem / sklearn_kernel_approximation_rbfsampler / sklearn_linear_model_logisticregression / sklearn_preprocessing_binarizer / sklearn_preprocessing_maxabsscaler / sklearn_preprocessing_minmaxscaler / sklearn_preprocessing_normalizer / sklearn_preprocessing_polynomialfeatures / sklearn_preprocessing_robustscaler / sklearn_preprocessing_standardscaler 
estimator = sklearn_ensemble_extratreesclassifier / sklearn_ensemble_gradientboostingclassifier / sklearn_ensemble_randomforestclassifier / sklearn_naive_bayes_bernoullinb / sklearn_naive_bayes_gaussiannb / sklearn_naive_bayes_multinomialnb / sklearn_neighbors_kneighborsclassifier / sklearn_svm_linearsvc / sklearn_tree_decisiontreeclassifier
affinity = "\"euclidean\"" / "\"l1\"" / "\"l2\"" / "\"manhattan\"" / "\"cosine\"" / "\"precomputed\""
linkage = "\"ward\"" / "\"complete\"" / "\"average\""
sklearn_cluster_featureagglomeration = "sklearn.cluster.FeatureAgglomeration" op "affinity" eq affinity cm "linkage" eq linkage cm cp
tol = "0.0001" / "0.001" / "1e-05" / "0.01" / "0.1"
sklearn_decomposition_fastica = "sklearn.decomposition.FastICA" op "tol" eq tol cm cp
iterated_power = "10" / "1" / "2" / "3" / "4" / "5" / "6" / "7" / "8" / "9"
svd_solver = "\"randomized\""
sklearn_decomposition_pca = "sklearn.decomposition.PCA" op "iterated_power" eq iterated_power cm "svd_solver" eq svd_solver cm cp
alpha = "0.001" / "100.0" / "0.01" / "10.0" / "0.1" / "1.0"
sklearn_feature_selection_selectfwe = "sklearn.feature_selection.SelectFwe" op "alpha" eq alpha cm cp
k = "10" / "11" / "12" / "13" / "14" / "15" / "16" / "17" / "18" / "19" / "20" / "21" / "22" / "23" / "24" / "25" / "26" / "27" / "28" / "29" / "30" / "31" / "32" / "33" / "34" / "35" / "36" / "37" / "38" / "39" / "40" / "41" / "42" / "43" / "44" / "45" / "46" / "47" / "48" / "49" / "50" / "51" / "52" / "53" / "54" / "55" / "56" / "57" / "58" / "59" / "60" / "61" / "62" / "63" / "64" / "65" / "66" / "67" / "68" / "69" / "70" / "71" / "72" / "73" / "74" / "75" / "76" / "77" / "78" / "79" / "80" / "81" / "82" / "83" / "84" / "85" / "86" / "87" / "88" / "89" / "90" / "91" / "92" / "93" / "94" / "95" / "96" / "97" / "98" / "99" / "1" / "2" / "3" / "4" / "5" / "6" / "7" / "8" / "9"
sklearn_feature_selection_selectkbest = "sklearn.feature_selection.SelectKBest" op "k" eq k cm cp
percentile = "10" / "11" / "12" / "13" / "14" / "15" / "16" / "17" / "18" / "19" / "20" / "21" / "22" / "23" / "24" / "25" / "26" / "27" / "28" / "29" / "30" / "31" / "32" / "33" / "34" / "35" / "36" / "37" / "38" / "39" / "40" / "41" / "42" / "43" / "44" / "45" / "46" / "47" / "48" / "49" / "50" / "51" / "52" / "53" / "54" / "55" / "56" / "57" / "58" / "59" / "60" / "61" / "62" / "63" / "64" / "65" / "66" / "67" / "68" / "69" / "70" / "71" / "72" / "73" / "74" / "75" / "76" / "77" / "78" / "79" / "80" / "81" / "82" / "83" / "84" / "85" / "86" / "87" / "88" / "89" / "90" / "91" / "92" / "93" / "94" / "95" / "96" / "97" / "98" / "99" / "1" / "2" / "3" / "4" / "5" / "6" / "7" / "8" / "9"
sklearn_feature_selection_selectpercentile = "sklearn.feature_selection.SelectPercentile" op "percentile" eq percentile cm cp
threshold = "0.15000000000000002" / "0.30000000000000004" / "0.35000000000000003" / "0.6000000000000001" / "0.7000000000000001" / "0.8500000000000001" / "0.9500000000000001" / "0.05" / "0.25" / "0.45" / "0.55" / "0.65" / "0.75" / "0.0" / "0.1" / "0.2" / "0.4" / "0.5" / "0.8" / "0.9" / "1.0"
sklearn_feature_selection_variancethreshold = "sklearn.feature_selection.VarianceThreshold" op "threshold" eq threshold cm cp
gamma = "0.15000000000000002" / "0.30000000000000004" / "0.35000000000000003" / "0.6000000000000001" / "0.7000000000000001" / "0.8500000000000001" / "0.9500000000000001" / "0.05" / "0.25" / "0.45" / "0.55" / "0.65" / "0.75" / "0.0" / "0.1" / "0.2" / "0.4" / "0.5" / "0.8" / "0.9" / "1.0"
kernel = "\"rbf\"" / "\"cosine\"" / "\"chi2\"" / "\"laplacian\"" / "\"polynomial\"" / "\"poly\"" / "\"linear\"" / "\"additive_chi2\"" / "\"sigmoid\""
n_components = "10" / "1" / "2" / "3" / "4" / "5" / "6" / "7" / "8" / "9"
sklearn_kernel_approximation_nystroem = "sklearn.kernel_approximation.Nystroem" op "gamma" eq gamma cm "kernel" eq kernel cm "n_components" eq n_components cm cp
sklearn_kernel_approximation_rbfsampler = "sklearn.kernel_approximation.RBFSampler" op "gamma" eq gamma cm cp
c = "0.0001" / "0.001" / "0.01" / "10.0" / "15.0" / "20.0" / "25.0" / "0.1" / "0.5" / "1.0" / "5.0"
dual = bool
penalty = "\"l1\"" / "\"l2\""
sklearn_linear_model_logisticregression = "sklearn.linear_model.LogisticRegression" op "C" eq c cm "dual" eq dual cm "penalty" eq penalty cm cp
sklearn_preprocessing_binarizer = "sklearn.preprocessing.Binarizer" op "threshold" eq threshold cm cp
sklearn_preprocessing_maxabsscaler = "sklearn.preprocessing.MaxAbsScaler" op cp
sklearn_preprocessing_minmaxscaler = "sklearn.preprocessing.MinMaxScaler" op cp
norm = "\"l1\"" / "\"l2\"" / "\"max\""
sklearn_preprocessing_normalizer = "sklearn.preprocessing.Normalizer" op "norm" eq norm cm cp
degree = "2"
include_bias = bool
interaction_only = bool
sklearn_preprocessing_polynomialfeatures = "sklearn.preprocessing.PolynomialFeatures" op "degree" eq degree cm "include_bias" eq include_bias cm "interaction_only" eq interaction_only cm cp
sklearn_preprocessing_robustscaler = "sklearn.preprocessing.RobustScaler" op cp
sklearn_preprocessing_standardscaler = "sklearn.preprocessing.StandardScaler" op cp
bootstrap = bool
criterion = "\"gini\"" / "\"entropy\""
max_features = "0.15000000000000002" / "0.35000000000000003" / "0.6000000000000001" / "0.6500000000000001" / "0.7000000000000001" / "0.7500000000000001" / "0.8500000000000001" / "0.9000000000000001" / "0.9500000000000001" / "0.05" / "0.25" / "0.45" / "0.55" / "0.1" / "0.2" / "0.3" / "0.4" / "0.5" / "0.8" / "1.0"
min_samples_leaf = "10" / "11" / "12" / "13" / "14" / "15" / "16" / "17" / "18" / "19" / "20" / "1" / "2" / "3" / "4" / "5" / "6" / "7" / "8" / "9"
min_samples_split = "10" / "11" / "12" / "13" / "14" / "15" / "16" / "17" / "18" / "19" / "20" / "2" / "3" / "4" / "5" / "6" / "7" / "8" / "9"
n_estimators = "100"
sklearn_ensemble_extratreesclassifier = "sklearn.ensemble.ExtraTreesClassifier" op "bootstrap" eq bootstrap cm "criterion" eq criterion cm "max_features" eq max_features cm "min_samples_leaf" eq min_samples_leaf cm "min_samples_split" eq min_samples_split cm "n_estimators" eq n_estimators cm cp
learning_rate = "0.001" / "0.01" / "0.1" / "0.5" / "1.0"
max_depth = "10" / "1" / "2" / "3" / "4" / "5" / "6" / "7" / "8" / "9"
subsample = "0.15000000000000002" / "0.35000000000000003" / "0.6000000000000001" / "0.6500000000000001" / "0.7000000000000001" / "0.7500000000000001" / "0.8500000000000001" / "0.9000000000000001" / "0.9500000000000001" / "0.05" / "0.25" / "0.45" / "0.55" / "0.1" / "0.2" / "0.3" / "0.4" / "0.5" / "0.8" / "1.0"
sklearn_ensemble_gradientboostingclassifier = "sklearn.ensemble.GradientBoostingClassifier" op "learning_rate" eq learning_rate cm "max_depth" eq max_depth cm "max_features" eq max_features cm "min_samples_leaf" eq min_samples_leaf cm "min_samples_split" eq min_samples_split cm "n_estimators" eq n_estimators cm "subsample" eq subsample cm cp
sklearn_ensemble_randomforestclassifier = "sklearn.ensemble.RandomForestClassifier" op "bootstrap" eq bootstrap cm "criterion" eq criterion cm "max_features" eq max_features cm "min_samples_leaf" eq min_samples_leaf cm "min_samples_split" eq min_samples_split cm "n_estimators" eq n_estimators cm cp
fit_prior = bool
sklearn_naive_bayes_bernoullinb = "sklearn.naive_bayes.BernoulliNB" op "alpha" eq alpha cm "fit_prior" eq fit_prior cm cp
sklearn_naive_bayes_gaussiannb = "sklearn.naive_bayes.GaussianNB" op cp
sklearn_naive_bayes_multinomialnb = "sklearn.naive_bayes.MultinomialNB" op "alpha" eq alpha cm "fit_prior" eq fit_prior cm cp
n_neighbors = "100" / "10" / "11" / "12" / "13" / "14" / "15" / "16" / "17" / "18" / "19" / "20" / "21" / "22" / "23" / "24" / "25" / "26" / "27" / "28" / "29" / "30" / "31" / "32" / "33" / "34" / "35" / "36" / "37" / "38" / "39" / "40" / "41" / "42" / "43" / "44" / "45" / "46" / "47" / "48" / "49" / "50" / "51" / "52" / "53" / "54" / "55" / "56" / "57" / "58" / "59" / "60" / "61" / "62" / "63" / "64" / "65" / "66" / "67" / "68" / "69" / "70" / "71" / "72" / "73" / "74" / "75" / "76" / "77" / "78" / "79" / "80" / "81" / "82" / "83" / "84" / "85" / "86" / "87" / "88" / "89" / "90" / "91" / "92" / "93" / "94" / "95" / "96" / "97" / "98" / "99" / "1" / "2" / "3" / "4" / "5" / "6" / "7" / "8" / "9"
p = "1" / "2"
weights = "\"uniform\"" / "\"distance\""
sklearn_neighbors_kneighborsclassifier = "sklearn.neighbors.KNeighborsClassifier" op "n_neighbors" eq n_neighbors cm "p" eq p cm "weights" eq weights cm cp
loss = "\"hinge\"" / "\"squared_hinge\""
sklearn_svm_linearsvc = "sklearn.svm.LinearSVC" op "C" eq c cm "dual" eq dual cm "loss" eq loss cm "penalty" eq penalty cm "tol" eq tol cm cp
sklearn_tree_decisiontreeclassifier = "sklearn.tree.DecisionTreeClassifier" op "criterion" eq criterion cm "max_depth" eq max_depth cm "min_samples_leaf" eq min_samples_leaf cm "min_samples_split" eq min_samples_split cm cp
op = "("
cp = ")"
cm = ","
eq = "="
bool = "True" / "False"
none = "None"
